
\section{本文工作}
本文借助了深度相机，以RGBD视频作为输入，
完成了一个从三维模型重建、位姿估计、模型形变捕捉到模型形变子空间构建的流程。
深度视频由按照时间顺序排列的深度图像构成。
与普通的图像不同，深度图像将场景中采样点距图像采集器的距离，即深度，作为其像素值，
它能够直观的描述场景的几何信息。
基于深度图像中记录的几何信息，本文实现了物体的三角网格模型的重建以及模型形变的捕捉，
并基于捕捉到的形变信息，构建了模型的合理的形变子空间，
使得模型在被修改的过程中发生的形变尽可能的接近落在这个子空间内的形状。

本文利用深度相机扫描物体，基于扫描过程中采集的深度信息重建三维模型。
深度图像记录了物体表面上的采样点与相机的相对位置。在扫描的过程中，本文会跟踪相机的运动轨迹，
得到每一帧的相机位置，从而计算出物体在全局坐标系中的位置。
在重建的步骤中，本文用体素描述三维模型，并根据每一帧深度图像更新体素的值。
体素模型可通过Matching Cubes\cite{lorensen1987marching}算法转换为三角网格模型。

在形变捕捉之前，本文需要估计物体的初始位姿。
本文首先从由RGBD图片生成的点云中分割出手部点云，
再通过手部点云的位置分割出物体的点云。
最后通过让网格模型与物体点云对齐估计出物体的初始位姿作为形变捕捉的初始位姿。

在获得了物体的静态三维模型和初始位姿后，本文需要用户摆弄物体使之发生形变，
并利用深度相机捕捉物体的形变，得到模型的形变关键帧。
在形变捕捉阶段，本文以静态三维模型与记录了物体形变过程的深度视频作为算法的输入，
得到一组形变后的模型作为该模型的形变关键帧。
本文用基于双四元数的形变图描述模型的形变。
对于每一帧，本文会优化形变图的参数，令形变后的模型和深度图像尽可能吻合，
从而得到发生形变后的模型，并挑选其中具有代表性的形变模型作为模型的形变关键帧。

然后，本文会从形变关键帧中提取出特征向量，构建模型的形变子空间。
从形变关键帧中提取的的特征向量描述了形变模型相对于静态模型的相对形变。
当静态模型已知时，特征向量和形变模型可以互相转换。
从形变关键帧中提取的特征向量称为关键向量，由特征向量张成的空间称为特征空间，即模型的形变子空间。
用户可以通过修改少数控制点修改模型，求解出一个落在特征空间内的特征向量和各个顶点的位置，
使得求解得到的模型形状和特征向量对应的形状尽可能接近。
由于形变关键帧是通过捕捉现实中物体的形变得到，所以所有的形变关键帧都是合理的，
由关键向量张成的形变子空间也是较为合理的。

算法\ref{alg_main_alg}是算法整体流程的伪代码。
其中第1行至第6行为三维重建的流程，将在第三章详细描述；
第7行至第10行为初始位姿估计流程，将在第四章详细描述；
第11行至第16行为形变捕捉与形变关键帧提取的流程，将在第五章详细描述；
第17至第20行为形变子空间构建的流程，将在第六章详细描述。
\begin{algorithm}
    %\fangsong
    \caption{本文算法流程}
    \label{alg_main_alg}
    \begin{algorithmic}[1]
        \For{each time $t$}
            \State Get depth frame
            \State Estimate the camera pose
            \State Fuse depth data into the global volume
        \EndFor
        \State Fetch mesh from the global volume
        \State Get RGBD frame for initial pose estimating
        \State Segment the hand point cloud
        \State Segment the object point cloud
        \State Match the mesh to the object point cloud to get the  initial pose
        \For{each time $t$}
            \State Get depth frame
            \State Optimize deformation parameters
        \EndFor
        \State Select representative deformation keyframes
        \State Align keyframes to the initial mesh
        \For{each keyframes}
            \State Fetch feature vector from keyframe
        \EndFor
        \State Build subspace with feature vectors
    \end{algorithmic}
\end{algorithm} 